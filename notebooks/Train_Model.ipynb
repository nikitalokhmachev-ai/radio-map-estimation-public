{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can use the button below to open this notebook in Google Colab. Note that changes made to the notebook in Colab will not be reflected in Github, nor can the notebook be saved on Colab without first making a copy. \n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nikitalokhmachev-ai/radio-map-estimation-public/blob/main/notebooks/Train_Model.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If opened in Colab, set `using_colab` to `True` in the code block below, then run the second and (optionally) third blocks. The second block will install the needed version of joblib for the data scaler to be loaded, then clone the github repository into Colab's local storage in order to load the models and other functions. The third block will connect to Google Drive (user login required), which allows the Colab notebook to read and write data to the drive (e.g. training data or evaluation results)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "using_colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if using_colab:\n",
        "    %cd /content/\n",
        "    !rm -rf /content/radio-map-estimation-public\n",
        "    !git clone https://github.com/nikitalokhmachev-ai/radio-map-estimation-public.git\n",
        "    !pip install -q -r /content/radio-map-estimation-public/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if using_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pv6cjhpNqyz"
      },
      "source": [
        "# Check GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is recommended to run this notebook with GPU support. If you have an Nvidea graphics card and drivers installed, the following block of code should show the details of the installed GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_MZ4vNCW5DV",
        "outputId": "1c1eb835-7289-4cb1-f3e3-5ae03e7207d8"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Untar Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the code block below, specify the path to the saved training data in tar format. This will untar the data into a folder of the same name in the parent directory of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUF595UIxGlm",
        "outputId": "855a7c95-f099-4d07-f389-351c0fa7858b"
      },
      "outputs": [],
      "source": [
        "# Train set\n",
        "!tar -xkf '/path/to/saved/tar/file' -C '/path/to/save/untarred/files'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80MkxCfJF9_T"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zWfrHtpz0pbf"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import joblib\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xFgICgWbu8A",
        "outputId": "c53258f1-644b-4122-f207-47e6167ec636"
      },
      "outputs": [],
      "source": [
        "# Import model architectures and data structures\n",
        "\n",
        "os.chdir('path/to/repository')\n",
        "from data_utils import MapDataset\n",
        "\n",
        "from models.autoencoders import BaselineAutoencoder\n",
        "from models.autoencoders import SkipAutoencoder, SkipResidualAutoencoder, SkipMaskAutoencoder, SkipMaskMapAutoencoder\n",
        "from models.autoencoders import SkipMapAutoencoder, SkipMapMaskAutoencoder, SkipInputAutoencoder\n",
        "from models.autoencoders import DualMaskAutoencoder, DualMaskMapAutoencoder, DualMapAutoencoder, DualMaskMapAutoencoder, DualInputAutoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4MY7viXdRn9"
      },
      "source": [
        "# Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wgsCKcuZdGdB"
      },
      "outputs": [],
      "source": [
        "# Set random seed, define device\n",
        "\n",
        "seed = 3\n",
        "torch.manual_seed(seed)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kQYvSUybdeAh"
      },
      "outputs": [],
      "source": [
        "# Set batch size, learning rate, and number of epochs\n",
        "train_batch_size = 256\n",
        "num_epochs = 1\n",
        "lr = 5e-4\n",
        "\n",
        "# Manually set values for buildings, unsampled locations, and sampled locations in the environment mask. \n",
        "# For the models in the PIMRC paper, these are set to \"None\", meaning they keep the default values of -1, 0, and 1 respectively.\n",
        "building_value = None\n",
        "unsampled_value = None\n",
        "sampled_value = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify the model architecture by selecting one of the classes imported above from models.autoencoders. Different hyperparameters can be set for each model, but the default values match the ones used in our experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify model type. Below we give an example for one of the models from the paper.\n",
        "model = SkipResidualAutoencoder().to(device)\n",
        "model_name = 'Skip_Residual.pth'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before running the following code block, create a folder to save the trained models, then enter the path to that folder in the variable `model_folder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set where to save the trained model weights\n",
        "model_folder = 'path/to/save/trained/model'\n",
        "\n",
        "if not os.path.exists(model_folder):\n",
        "    os.makedirs(model_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify paths to untarred training data and data scaler\n",
        "train_data_folder = 'path/to/untarred/training/data'\n",
        "scaler_path = 'scalers/minmax_scaler_zero_min134.joblib'\n",
        "\n",
        "assert os.path.isdir(train_data_folder)\n",
        "assert os.path.exists(scaler_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Training data into DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEpL79nFeQ-K",
        "outputId": "14aebd2b-921b-4b52-c4d7-1d3e84edc2ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/william/RadioMap/pimrc_test_env/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_pickle_path = os.path.join(train_data_folder, '*.pickle')\n",
        "train_pickles = glob.glob(train_pickle_path)\n",
        "\n",
        "with open(scaler_path, 'rb') as f:\n",
        "  scaler = joblib.load(f)\n",
        "\n",
        "train_ds = MapDataset(train_pickles, scaler=scaler, building_value=building_value, sampled_value=sampled_value)\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=train_batch_size, shuffle=False)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uE-E_SKfDPn"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y6vmIID1fEZZ",
        "outputId": "f20ef565-454c-4988-83a4-18fcbdb85d8a"
      },
      "outputs": [],
      "source": [
        "model.fit(train_dl, optimizer, epochs=num_epochs, loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKoQOYELfL04"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ln6If5_PfNC4"
      },
      "outputs": [],
      "source": [
        "model.save_model(os.path.join(model_folder, model_name))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
