{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can use the button below to open this notebook in Google Colab. Note that changes made to the notebook in Colab will not be reflected in Github, nor can the notebook be saved on Colab without first making a copy. \n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nikitalokhmachev-ai/radio-map-estimation-public/blob/main/notebooks/Visualize_Results.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If opened in Colab, set `using_colab` to `True` in the code block below, then run the second and (optionally) third blocks. The second block will install kaleido to visualize some of the results, then clone the github repository into Colab's local storage in order to load the models and other functions. The third block will connect to Google Drive (user login required), which allows the Colab notebook to read and write data to the drive (e.g. training data or evaluation results)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "using_colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if using_colab:\n",
        "    %cd /content/\n",
        "    !rm -rf /content/radio-map-estimation-public\n",
        "    !git clone https://github.com/nikitalokhmachev-ai/radio-map-estimation-public.git\n",
        "    !pip install -q -r /content/radio-map-estimation-public/colab_requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if using_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yttrJ663TPK"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWfrHtpz0pbf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir('path/to/repository')\n",
        "from test_utils import get_sample_error, visualize_sample_error, get_average_error, visualize_average_error, visualize_hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model and Result Paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify paths to the folders where the trained models are saved, where the results are saved, and where the visualizations (graphs) should be saved. For the PIMRC paper, we included some graphs showing all models' performance, and some graphs showing just the performance of Dual Path or UNet models. Below, we specify a single folder for `all_results`, and then two folders for `dual_results` and `unet_results`. One way to accomplish this is to have the Dual Path and UNet result folders saved under an overarching folder for All results, then conclude the path to the All results folder with `\\**`, which indicates a recursive search within that folder when using the `glob` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfeTolRbuONY"
      },
      "outputs": [],
      "source": [
        "# Specify folder containing trained models\n",
        "model_folder = '/Path/to/saved/models'\n",
        "\n",
        "# Specify folder containing all saved results\n",
        "all_results = '/Path/to/saved/results'\n",
        "\n",
        "# Specify folder containing Dual Path saved results\n",
        "dual_results = '/Path/to/dual_path/results'\n",
        "\n",
        "# Specify folder containing Skip Connection saved results\n",
        "unet_results = '/Path/to/UNet/results'\n",
        "\n",
        "# Set folder to save visualizations\n",
        "viz_folder = '/Path/to/save/visualizations'\n",
        "if not os.path.exists(viz_folder):\n",
        "    os.makedirs(viz_folder)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Display Names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is optional code to specify how model names will appear in visualizations. \n",
        "\n",
        "`display_names` is a dictionary, the keys of which are the names that the individual model results are saved under (minus the \".pickle\" ending), and the values of which are how they will appear in visualizations. Below are the names of the models as they were saved and appear in the PIMRC paper. `display_names` is provided as an optional parameter to the `visualize_sample_error` function; if `None` (the default), the models will be named according to their filenames in the results folder.\n",
        "\n",
        "`consistent_colors` is a dictionary that attaches an index to each model name in order to ensure the same model is depicted using the same color in any line graphs. `consistent_colors` is provided as an optional parameter to the `visualize_sample_error` function; if `None` (the default), models will be assigned arbitrary colors that may vary between graphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMTR-zzhtiF2"
      },
      "outputs": [],
      "source": [
        "display_names = {'Baseline':'Baseline', 'Dual Concat Mask Only':'Dual<sub>mask</sub>', 'Dual Concat Map Only':'Dual<sub>map</sub>',\n",
        "               'Dual Concat Mask then Map':'Dual<sub>mask-map</sub>', 'Dual Concat Map then Mask':'Dual<sub>map-mask</sub>',\n",
        "               'Dual Concat Input':'Dual<sub>input</sub>', 'UNet Baseline':'Skip', 'UNet Concat Input':'Skip<sub>input</sub>',\n",
        "               'UNet Concat Map Only':'Skip<sub>map</sub>','UNet Concat Mask Only':'Skip<sub>mask</sub>',\n",
        "               'UNet Concat Map then Mask':'Skip<sub>map-mask</sub>', 'UNet Concat Mask then Map':'Skip<sub>mask-map</sub>',\n",
        "               'UNet Concat Input': 'Skip<sub>input</sub>', 'ResUNet':'Skip<sub>residual</sub>'}\n",
        "consistent_colors = {v[1]:v[0] for v in enumerate(display_names.values())}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTNtiFzt3cUT"
      },
      "source": [
        "# Results Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Average Error for All Models (Table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH7fk2AWTilx"
      },
      "outputs": [],
      "source": [
        "avg_dfs = get_average_error(all_results)\n",
        "avg_dfs = avg_dfs.set_index('Model')\n",
        "avg_dfs = avg_dfs.sort_values(['Avg Error'])\n",
        "avg_dfs.index.name = None\n",
        "avg_dfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Size Comparison (Table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70tI0WIZNfNf"
      },
      "outputs": [],
      "source": [
        "mdl_names = avg_dfs.index\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "models = dict()\n",
        "for name in mdl_names:\n",
        "  model = torch.load(os.path.join(model_folder, name + '.pth'), weights_only=False, map_location=device)\n",
        "  models[name] = model\n",
        "\n",
        "params = {'Encoder':[], 'Decoder':[], 'Total':[]}\n",
        "for model in models.values():\n",
        "  params['Encoder'].append(count_parameters(model.encoder))\n",
        "  params['Decoder'].append(count_parameters(model.decoder))\n",
        "  params['Total'].append(count_parameters(model))\n",
        "  assert(params['Encoder'][-1] + params['Decoder'][-1] == params['Total'][-1])\n",
        "\n",
        "params_df = pd.DataFrame.from_dict(params, orient='columns')\n",
        "params_df.index = models.keys()\n",
        "params_df = params_df.sort_values(['Total'])\n",
        "params_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Size vs Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyQX6OkkylHG"
      },
      "outputs": [],
      "source": [
        "df_vis = params_df.join(avg_dfs)\n",
        "df_vis['TotalVis'] = df_vis['Total'] - df_vis['Total'].min() + 2000\n",
        "df_vis['Text'] = (df_vis['Total'] // 1000).astype(str) + 'K'\n",
        "df_vis['Model'] = df_vis.index\n",
        "df_vis['Neg Error'] = df_vis['Avg Error'] * -1\n",
        "df_vis=df_vis.sort_values(['Total', 'Neg Error'])\n",
        "df_vis.reindex([])\n",
        "df_vis = df_vis.replace({'Model': display_names})\n",
        "df_vis['Colors'] = df_vis['Model'].copy()\n",
        "df_vis.replace({'Colors': consistent_colors})\n",
        "\n",
        "fig = px.scatter(df_vis, x=\"Model\", y=\"Avg Error\", size=\"TotalVis\", color=\"Model\", size_max=90, text='Text', labels=display_names)\n",
        "fig.update_traces(textposition='top center')\n",
        "fig.update_layout(plot_bgcolor='rgba(0, 0, 0, 0)')\n",
        "fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n",
        "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n",
        "fig.update_yaxes(range=[1.64, 2.25])\n",
        "fig.update_layout(showlegend=False, yaxis_title='RMSE(dB)')\n",
        "fig.update_layout(width=1500, height=800)\n",
        "fig.update_layout(font=dict(size=34))\n",
        "\n",
        "fig.update_layout(shapes=[go.layout.Shape(type='rect', xref='paper', yref='paper', x0=0, y0=0, x1=1, y1=1, line={'width': 1, 'color': 'black', 'dash':'solid'})])\n",
        "fig.update_xaxes(\n",
        "  ticks=\"outside\",\n",
        "  tickson=\"labels\",\n",
        "  ticklen=15,\n",
        "  title=None)\n",
        "fig.update_yaxes(\n",
        "    ticks=\"outside\",\n",
        "    tickson=\"labels\",\n",
        "    ticklen=15)\n",
        "\n",
        "fig.show()\n",
        "fig.write_image(os.path.join(viz_folder, 'All Models Size.pdf'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dual Path Models Average Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7oBnQEG-GR2"
      },
      "outputs": [],
      "source": [
        "dual_avg_df = get_average_error(dual_results)\n",
        "dual_avg_df = dual_avg_df.sort_values('Avg Error', ascending=False)\n",
        "\n",
        "# Full figure\n",
        "fig = visualize_average_error(dual_avg_df, display_names=display_names, baseline_name='Baseline', \n",
        "                              width=700, height=450, text_size=24)\n",
        "fig.write_image(os.path.join(viz_folder,'Dual Path Avg.pdf'))\n",
        "\n",
        "# Zoomed in figure (used in paper)\n",
        "fig = visualize_average_error(dual_avg_df, display_names=display_names, baseline_name='Baseline', \n",
        "                              width=700, height=450, text_size=24, y_range=[1.5, 2.4])\n",
        "fig.write_image(os.path.join(viz_folder,'Dual Path Avg Zoom.pdf'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dual Path Models per-Sampling Rate Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf7X6dEPGXK6"
      },
      "outputs": [],
      "source": [
        "dashes = ['dash','solid']\n",
        "markers = ['star', 'diamond', 'square']\n",
        "line_styles = [(d, m) for m in markers for d in dashes]\n",
        "\n",
        "# Full figure (used in paper)\n",
        "fig = visualize_sample_error(dual_results, display_names=display_names, consistent_colors=consistent_colors, line_styles=line_styles, width=700, height=450, text_size=23, marker_size=10)\n",
        "fig.write_image('Dual Path All.pdf')\n",
        "\n",
        "# Zoomed in figure\n",
        "fig = visualize_sample_error(dual_results, display_names=display_names, consistent_colors=consistent_colors, line_styles=line_styles, width=700, height=450, text_size=23, marker_size=10, y_range=[0.9, 3.3], x_range=[0,0.4])\n",
        "fig.write_image(os.path.join(viz_folder, 'Dual Path All Zoom.pdf'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dual Path Models Average Split by Sampling Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Figure not used in paper\n",
        "fig = visualize_hist(dual_results, display_names=display_names, baseline_name='Baseline', \n",
        "                     text_size=23, width=700, height=450)\n",
        "fig.write_image(\"Dual Path Bins.pdf\")\n",
        "\n",
        "# Figure not used in paper\n",
        "fig = visualize_hist(dual_results, display_names=display_names, baseline_name='Baseline', \n",
        "                     text_size=23, width=700, height=450, y_range=[0.5, 3.2])\n",
        "fig.write_image(\"Dual Path Bins Zoom.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## UNet Models Average Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaVoTPebHVA5"
      },
      "outputs": [],
      "source": [
        "unet_avg_df = get_average_error(unet_results)\n",
        "unet_avg_df = unet_avg_df.sort_values('Avg Error', ascending=False)\n",
        "\n",
        "# Figure not used in paper\n",
        "fig = visualize_average_error(unet_avg_df, display_names=display_names, baseline_name='Baseline', \n",
        "                              width=700, height=450, text_size=24)\n",
        "fig.write_image(os.path.join(viz_folder, 'UNet Avg.pdf'))\n",
        "\n",
        "# Figure not used in paper\n",
        "fig = visualize_average_error(unet_avg_df, display_names=display_names, baseline_name='Baseline', \n",
        "                              width=700, height=450, text_size=24, y_range=[1.5, 2.4])\n",
        "fig.write_image(os.path.join(viz_folder,'UNet Avg Zoom.pdf'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## UNet Models per-Sampling Rate Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2oGLGYZE3mA"
      },
      "outputs": [],
      "source": [
        "dashes = ['solid', 'dash', 'dot']\n",
        "markers = ['circle', 'square', 'diamond']\n",
        "line_styles = [(d, m) for m in markers for d in dashes]\n",
        "\n",
        "# Full figure (used in paper)\n",
        "fig = visualize_sample_error(unet_results, display_names=display_names, consistent_colors=consistent_colors, line_styles=line_styles, text_size=24, width=700, height=450, marker_size=10)\n",
        "fig.write_image(os.path.join(viz_folder,\"Unet All.pdf\"))\n",
        "\n",
        "# Zoomed in figure\n",
        "fig = visualize_sample_error(unet_results, display_names=display_names, consistent_colors=consistent_colors, line_styles=line_styles, text_size=24, width=700, height=450, marker_size=10, y_range=[0.9, 3.3], x_range=[0,0.4])\n",
        "fig.write_image(os.path.join(viz_folder,\"Unet All Zoom.pdf\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## UNet Models Average Error Split by Sampling Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH6sUy7p8Clv"
      },
      "outputs": [],
      "source": [
        "# Full figure\n",
        "fig = visualize_hist(unet_results, display_names=display_names, baseline_name='Baseline',\n",
        "                     text_size=23, width=700, height=450)\n",
        "fig.write_image(\"UNet Bins.pdf\")\n",
        "\n",
        "# Zoomed in figure (used in paper)\n",
        "fig = visualize_hist(unet_results, display_names=display_names, baseline_name='Baseline',\n",
        "                     text_size=23, width=700, height=450, y_range=[0.5, 3])\n",
        "fig.write_image(\"UNet Bins Zoom.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## All Models Average Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-eqEUbArhd1"
      },
      "outputs": [],
      "source": [
        "vis_avg_df = avg_dfs.copy()\n",
        "vis_avg_df['Model'] = vis_avg_df.index\n",
        "vis_avg_df = vis_avg_df.sort_values('Avg Error', ascending=False)\n",
        "\n",
        "# Figure not used in paper\n",
        "fig = visualize_average_error(vis_avg_df, display_names=display_names, baseline_name='Baseline', \n",
        "                              width=1200, height=450, text_size=24)\n",
        "fig.write_image(os.path.join(viz_folder, \"All Models Average.pdf\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dual Path vs UNet per Sampling Rate Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To compare Dual Path and UNet models without overly cluttering the graph, we visualize just the median performing models of each group and the Baseline. In fact, we include two medians for the Dual Path group, those that pass the sampled map to the Decoder (Top) and those that pass the environment mask (Bottom), since there is significant difference between these groups.\n",
        "\n",
        "To do this, we copy the median model performances to a new `group_folder` then pass this folder to the `visualize_sample_error` function along with a new `model_group_names` dictionary to rename each according to its group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LgsF1BUtJ16"
      },
      "outputs": [],
      "source": [
        "group_folder = '/Path/to/group/folder'\n",
        "model_group_names = {'Baseline':'Baseline', 'Dual Concat Mask Only':'Dual Path Models (Bottom)', \n",
        "                     'Dual Concat Mask then Map':'Dual Path Models (Top)', 'UNet Concat Mask Only':'Skip Connection Models'}\n",
        "\n",
        "dashes = ['solid', 'dash', 'dot']\n",
        "markers = ['circle', 'square', 'diamond', 'star']\n",
        "line_styles = [(d, m) for d in dashes for m in markers]\n",
        "\n",
        "# Full figure (used in paper)\n",
        "fig = visualize_sample_error(group_folder, display_names=model_group_names, consistent_colors=consistent_colors, \n",
        "                             width=700, height=450, text_size=23, line_styles=line_styles, marker_size=10)\n",
        "fig.write_image(os.path.join(viz_folder, \"Model Groups All.pdf\"))\n",
        "\n",
        "# Zoomed in figure\n",
        "fig = visualize_sample_error(group_folder, display_names=model_group_names, consistent_colors=consistent_colors, \n",
        "                             width=700, height=450, text_size=23, line_styles=line_styles, marker_size=10, y_range=[0.9, 3.3], x_range=[0, 0.4])\n",
        "fig.write_image(os.path.join(viz_folder, \"Model Groups All Zoom.pdf\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
