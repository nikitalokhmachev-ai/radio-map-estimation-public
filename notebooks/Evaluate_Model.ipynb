{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can use the button below to open this notebook in Google Colab. Note that changes made to the notebook in Colab will not be reflected in Github, nor can the notebook be saved on Colab without first making a copy. \n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nikitalokhmachev-ai/radio-map-estimation-public/blob/main/notebooks/Evaluate_Model.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If opened in Colab, set `using_colab` to `True` in the code block below, then run the second and (optionally) third blocks. The second block will clone the github repository into Colab's local storage in order to load the models and other functions. The third block will connect to Google Drive (user login required), which allows the Colab notebook to read and write data to the drive (e.g. training data or evaluation results)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "using_colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if using_colab:\n",
        "    %cd /content/\n",
        "    !rm -rf /content/radio-map-estimation-public\n",
        "    !git clone https://github.com/nikitalokhmachev-ai/radio-map-estimation-public.git\n",
        "    !pip install -q -r /content/radio-map-estimation-public/colab_requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if using_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Check GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is recommended to run this notebook with GPU support. If you have an Nvidea graphics card and drivers installed, the following block of code should show the details of the installed GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Untar Testing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the code block below, specify the path to the saved testing data in tar format. This will untar the data into a folder of the same name in the parent directory of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUF595UIxGlm"
      },
      "outputs": [],
      "source": [
        "!tar -xkf '/path/to/saved/tar/file' -C '/path/to/save/untarred/files'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWfrHtpz0pbf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import model architectures and data structures\n",
        "\n",
        "os.chdir('path/to/repository')\n",
        "from test_utils import get_model_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set random seed, define device\n",
        "\n",
        "seed = 3\n",
        "torch.manual_seed(seed)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set batch size\n",
        "test_batch_size = 1024\n",
        "\n",
        "# Manually set values for buildings, unsampled locations, and sampled locations in the environment mask. \n",
        "# For the models in the PIMRC paper, these are set to \"None\", meaning they keep the default values of -1, 0, and 1 respectively.\n",
        "building_value = None\n",
        "unsampled_value = None\n",
        "sampled_value = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the folder to load trained models from. All models in the selected model_folder will be tested. Additionally create and specify a folder to save the results to, and specify the paths to the saved data and data scaler (located within this repository)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1ax78Ucwaa8"
      },
      "outputs": [],
      "source": [
        "# Specify folder containing trained models\n",
        "model_folder = '/folder/with/trained/models'\n",
        "\n",
        "# Specify path to untarred test data\n",
        "test_data_folder = '/path/to/untarred/testing/data'\n",
        "\n",
        "# Specify path to data scaler\n",
        "scaler_path = 'scalers/minmax_scaler_zero_min134.joblib'\n",
        "\n",
        "# Set folder to save current results\n",
        "results_folder = '/folder/to/save/results'\n",
        "if not os.path.exists(results_folder):\n",
        "    os.makedirs(results_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w21gqRPMvVkw"
      },
      "outputs": [],
      "source": [
        "model_names = glob.glob(os.path.join(model_folder, '*.pth'))\n",
        "for model_path in model_names:\n",
        "  error = get_model_error(test_data_folder, test_batch_size, model_path, scaler_path, building_value=building_value, sampled_value=sampled_value)\n",
        "  filename = os.path.basename(model_path).split('.')[0] + '.pickle'\n",
        "  with open(os.path.join(results_folder, filename), 'wb') as f:\n",
        "    pickle.dump(error, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
